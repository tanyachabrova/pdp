{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd326e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "import matplotlib.pyplot as plt\n",
    "from music21 import converter, stream\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pickle\n",
    "import json\n",
    "from matplotlib import image as mpimg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        print(\"GPU is available.\")\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    else:\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "\n",
    "\n",
    "def load_midi_files(file_directory):\n",
    "    midi_files = []\n",
    "    for root, dirs, files in os.walk(file_directory): \n",
    "        print(f\"Checking folder: {root}\") \n",
    "        for file in files:\n",
    "            if file.endswith(\".midi\") or file.endswith(\".mid\"): \n",
    "                midi_files.append(os.path.join(root, file)) \n",
    "    return midi_files\n",
    "\n",
    "def load_midi(file_path):\n",
    "    midi = MidiFile(file_path)\n",
    "    notes = []\n",
    "    for i, track in enumerate(midi.tracks):\n",
    "        for msg in track:\n",
    "            if msg.type == 'note_on': \n",
    "                notes.append(msg.note)\n",
    "    return notes\n",
    "\n",
    "\n",
    "def pca_feature_extraction(data, n_components=32):\n",
    "    print(f\"Starting PCA with {n_components} components...\")\n",
    "\n",
    "    n_features = data.shape[1]  # Number of features (sequence length)\n",
    "    n_components = min(n_components, n_features)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(data)\n",
    "    print(\"PCA has been completed.\")\n",
    "    return pca_result\n",
    "\n",
    "def prepare_sequences(data, sequence_length=32):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i+sequence_length]\n",
    "        sequences.append(seq)\n",
    "        labels.append(data[i+sequence_length])\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "\n",
    "def train_lstm(sequences, labels, input_shape, num_classes, epochs=20, batch_size=32):\n",
    "    print(f\"Starting LSTM model training with {epochs} epochs and batch size {batch_size}...\")\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "        tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(sequences, labels, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])\n",
    "    print(\"LSTM training has been completed.\")\n",
    "    return model, history\n",
    "\n",
    "def kmeans_clustering(data, n_clusters=128):\n",
    "    print(\"Starting K-means clustering...\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(data)\n",
    "    print(\"K-means clustering has been completed.\")\n",
    "    return kmeans.predict(data)\n",
    "\n",
    "def convert_to_midi(clusters, output_filename=\"output_midi.mid\"):\n",
    "    print(f\"Converting clusters to MIDI: {output_filename}...\")\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    for note in clusters:\n",
    "        msg = Message('note_on', note=note, velocity=64, time=0)\n",
    "        track.append(msg)\n",
    "        msg = Message('note_off', note=note, velocity=64, time=100)\n",
    "        track.append(msg)\n",
    "    midi_file.save(output_filename)\n",
    "    print(f\"MIDI file saved as: {output_filename}\")\n",
    "\n",
    "\n",
    "def convert_midi_to_music_representation(midi_data):\n",
    "    music_rep = converter.parse(midi_data)\n",
    "    return music_rep\n",
    "\n",
    "\n",
    "def export_sheet_music(sheet_music, output_format, filename):\n",
    "    sheet_music.write(output_format, fp=filename)\n",
    "\n",
    "\n",
    "def prepare_midi_data(midi_files):\n",
    "    print(\"Preparing MIDI data...\")\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for midi_file in tqdm(midi_files, desc=\"Loading MIDI files\"):\n",
    "        midi_notes = load_midi(midi_file)  \n",
    "        sequences_midi, labels_midi = prepare_sequences(midi_notes) \n",
    "        sequences.extend(sequences_midi)\n",
    "        labels.extend(labels_midi)\n",
    "\n",
    "    print(\"Applying PCA to the data...\")\n",
    "    sequences_pca = pca_feature_extraction(sequences)\n",
    "    \n",
    "    sequences_pca = np.expand_dims(np.array(sequences_pca), axis=-1)\n",
    "    print(\"MIDI data preparation is complete.\")\n",
    "    return sequences_pca, np.array(labels)\n",
    "\n",
    "\n",
    "def cache_midi_files(file_directory, cache_file):\n",
    "    midi_files = load_midi_files(file_directory)\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(midi_files, f) \n",
    "    print(f\"Saved {len(midi_files)} MIDI file paths to cache at {cache_file}.\")\n",
    "    return midi_files\n",
    "\n",
    "\n",
    "def load_cached_midi_files(cache_file):\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Loading cached MIDI files from: {cache_file}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            midi_files = pickle.load(f) \n",
    "        print(f\"Loaded {len(midi_files)} MIDI file paths from cache.\")\n",
    "        return midi_files\n",
    "    else:\n",
    "        print(\"No cache found. Loading MIDI files from the dataset...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_model(model, model_path):\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "def save_results(val_loss, val_accuracy, results_path):\n",
    "    results = {\n",
    "        \"validation_loss\": val_loss,\n",
    "        \"validation_accuracy\": val_accuracy\n",
    "    }\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"Results saved at: {results_path}\")\n",
    "\n",
    "def load_model_from_disk(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded from: {model_path}\")\n",
    "    return model\n",
    "\n",
    "def plot_training_history(history):\n",
    "    print(\"Plotting training history...\")\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_sheet_music_from_new_midi(input_midi_path, model, sequence_length=32):\n",
    "    print(\"Generating sheet music from new MIDI file...\")\n",
    "\n",
    "    midi_notes = load_midi(input_midi_path)  \n",
    "    input_sequences, _ = prepare_sequences(midi_notes, sequence_length)\n",
    "    \n",
    "    predicted_notes = model.predict(input_sequences)\n",
    "    \n",
    "    output_midi_path = 'predicted_output_midi.mid'\n",
    "    generate_midi(predicted_notes[0], output_filename=output_midi_path)\n",
    "    print(f\"Generated MIDI file saved as: {output_midi_path}\")\n",
    "\n",
    "    music_representation = convert_midi_to_music_representation(output_midi_path)\n",
    "    \n",
    "    output_pdf_path = 'predicted_sheet_music.pdf'\n",
    "    music_representation.write('pdf', fp=output_pdf_path)\n",
    "    print(f\"Sheet music has been exported to: {output_pdf_path}\")\n",
    "\n",
    "def main(extracted_folder, cache_file, model_save_path, results_save_path):\n",
    "\n",
    "    check_gpu()\n",
    "\n",
    "    midi_files = load_cached_midi_files(cache_file)\n",
    "    \n",
    "    if midi_files is None: \n",
    "        midi_files = []\n",
    "        for year_folder in range(2004, 2019):  \n",
    "            midi_folder = os.path.join(extracted_folder, f'{year_folder}')\n",
    "            midi_files_in_year = load_midi_files(midi_folder) \n",
    "            midi_files.extend(midi_files_in_year)\n",
    "        \n",
    "        if len(midi_files) == 0:\n",
    "            print(\"No MIDI files found. Please check the extraction and folder paths.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Loaded {len(midi_files)} MIDI files from the MAESTRO dataset.\")\n",
    "\n",
    "        cache_midi_files(extracted_folder, cache_file)\n",
    "    \n",
    "    sequences, labels = prepare_midi_data(midi_files)\n",
    "    \n",
    "    train_sequences, val_sequences, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "    print(f\"Training Sequences Shape: {train_sequences.shape}\")\n",
    "    print(f\"Validation Sequences Shape: {val_sequences.shape}\")\n",
    "\n",
    "    input_shape = train_sequences.shape[1:] \n",
    "    num_classes = np.max(train_labels) + 1 \n",
    "\n",
    "    model = train_lstm(train_sequences, train_labels, input_shape, num_classes, epochs=5, batch_size=16)\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(val_sequences, val_labels)\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    save_model(model, model_save_path)\n",
    "    save_results(val_loss, val_accuracy, results_save_path)\n",
    "\n",
    "    clusters = kmeans_clustering(val_sequences)\n",
    "\n",
    "    convert_to_midi(clusters)\n",
    "\n",
    "    music_representation = convert_midi_to_music_representation(\"output_midi.mid\")\n",
    "    sheet_music = music_representation\n",
    "    output_file_path_XML = \"./resultXML/\" + os.path.splitext(os.path.basename(extracted_folder))[0] + \".xml\"\n",
    "    output_file_path_PDF = \"./resultPDF/\" + os.path.splitext(os.path.basename(extracted_folder))[0] + \".pdf\"\n",
    "    export_sheet_music(sheet_music, \"musicxml\", output_file_path_XML)\n",
    "\n",
    "    print(f\"MIDI file has been converted and saved as 'output_midi.mid'.\")\n",
    "    print(f\"Sheet music exported as MusicXML: {output_file_path_XML}\")\n",
    "    print(f\"Sheet music exported as PDF: {output_file_path_PDF}\")\n",
    "\n",
    "    plot_training_history(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_folder = r'C:\\Users\\BoilingMachine\\OneDrive\\Desktop\\Diploma\\maestro-v3.0.0'\n",
    "\n",
    "cache_file = r'C:\\Users\\BoilingMachine\\OneDrive\\Desktop\\Diploma\\maestro-v3.0.0\\midi_files_cache.pkl'\n",
    "\n",
    "model_save_path = r'./saved_model/my_model'\n",
    "results_save_path = r'./saved_model/results.json'\n",
    "\n",
    "main(extracted_folder, cache_file, model_save_path, results_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
